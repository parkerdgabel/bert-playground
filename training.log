2025-07-17 09:20:57.644 | INFO     | utils.mlx_patch:apply_mlx_patches:77 - Applying MLX compatibility patches...
2025-07-17 09:20:57.644 | INFO     | utils.mlx_patch:patch_mlx_astype:72 - Applied MLX astype() compatibility patch
2025-07-17 09:20:57.644 | INFO     | utils.mlx_patch:apply_mlx_patches:79 - MLX compatibility patches applied successfully
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.

MLX Unified Training System
============================================================

Loading data...
2025-07-17 09:21:01.246 | INFO     | data.mlx_dataloader:__init__:82 - Loading tokenizer: mlx-community/answerdotai-ModernBERT-base-4bit (backend: auto)
2025-07-17 09:21:01.246 | INFO     | embeddings.mlx_adapter:_load_mlx_embeddings:55 - Loading MLX embeddings model: mlx-community/answerdotai-ModernBERT-base-4bit
Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 9245.34it/s]
2025-07-17 09:21:01.666 | INFO     | embeddings.mlx_adapter:_load_mlx_embeddings:58 - Successfully loaded MLX embeddings model
2025-07-17 09:21:01.666 | INFO     | embeddings.tokenizer_wrapper:_initialize_backend:59 - Using MLX embeddings tokenizer
2025-07-17 09:21:01.667 | DEBUG    | data.mlx_dataloader:_analyze_csv:133 - CSV columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']
2025-07-17 09:21:01.667 | DEBUG    | data.mlx_dataloader:_analyze_csv:134 - Text columns: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']
2025-07-17 09:21:01.667 | DEBUG    | data.mlx_dataloader:_analyze_csv:135 - Has labels: True
2025-07-17 09:21:01.667 | INFO     | data.mlx_dataloader:_preprocess_data:139 - Preprocessing data...
2025-07-17 09:21:01.813 | INFO     | data.mlx_dataloader:_preprocess_data:173 - Preprocessed 891 samples
2025-07-17 09:21:01.813 | INFO     | data.mlx_dataloader:__init__:104 - Initialized KaggleDataLoader: 891 samples, 55 batches
2025-07-17 09:21:01.813 | INFO     | data.mlx_dataloader:__init__:82 - Loading tokenizer: mlx-community/answerdotai-ModernBERT-base-4bit (backend: auto)
2025-07-17 09:21:01.813 | INFO     | embeddings.mlx_adapter:_load_mlx_embeddings:55 - Loading MLX embeddings model: mlx-community/answerdotai-ModernBERT-base-4bit
Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 11032.80it/s]
2025-07-17 09:21:01.980 | INFO     | embeddings.mlx_adapter:_load_mlx_embeddings:58 - Successfully loaded MLX embeddings model
2025-07-17 09:21:01.980 | INFO     | embeddings.tokenizer_wrapper:_initialize_backend:59 - Using MLX embeddings tokenizer
2025-07-17 09:21:01.981 | DEBUG    | data.mlx_dataloader:_analyze_csv:133 - CSV columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']
2025-07-17 09:21:01.981 | DEBUG    | data.mlx_dataloader:_analyze_csv:134 - Text columns: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']
2025-07-17 09:21:01.981 | DEBUG    | data.mlx_dataloader:_analyze_csv:135 - Has labels: True
2025-07-17 09:21:01.981 | INFO     | data.mlx_dataloader:_preprocess_data:139 - Preprocessing data...
2025-07-17 09:21:02.010 | INFO     | data.mlx_dataloader:_preprocess_data:173 - Preprocessed 178 samples
2025-07-17 09:21:02.010 | INFO     | data.mlx_dataloader:__init__:104 - Initialized KaggleDataLoader: 178 samples, 5 batches
âœ“ Loaded ~896 training samples (56 batches)
âœ“ Loaded ~192 validation samples (6 batches)
2025-07-17 09:21:02.011 | INFO     | training.config:_validate_config:373 - Configuration validation passed
                          Training Configuration                          
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter             â”ƒ Value                                          â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Model                 â”‚ mlx-community/answerdotai-ModernBERT-base-4bit â”‚
â”‚ Model Type            â”‚ base                                           â”‚
â”‚ Output Directory      â”‚ output/run_20250717_092101                     â”‚
â”‚ MLX Embeddings        â”‚ Enabled                                        â”‚
â”‚ Tokenizer Backend     â”‚ auto                                           â”‚
â”‚ Batch Size            â”‚ 16                                             â”‚
â”‚ Learning Rate         â”‚ 2e-05                                          â”‚
â”‚ Epochs                â”‚ 3                                              â”‚
â”‚ Gradient Accumulation â”‚ 1                                              â”‚
â”‚ MLflow                â”‚ Enabled                                        â”‚
â”‚ Early Stopping        â”‚ 3                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
2025-07-17 09:21:02.015 | INFO     | models.embeddings.mlx_adapter:_load_mlx_embeddings:55 - Loading MLX embeddings model: mlx-community/answerdotai-ModernBERT-base-4bit
Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 15042.33it/s]
2025-07-17 09:21:02.218 | INFO     | models.embeddings.mlx_adapter:_load_mlx_embeddings:58 - Successfully loaded MLX embeddings model
2025-07-17 09:21:02.218 | INFO     | models.embeddings.embedding_model:__init__:64 - Initialized EmbeddingModel: mlx-community/answerdotai-ModernBERT-base-4bit (hidden_size=768)
2025-07-17 09:21:02.218 | INFO     | models.classification.titanic_classifier:__init__:64 - Initialized TitanicClassifier with mlx-community/answerdotai-ModernBERT-base-4bit
2025-07-17 09:21:02.218 | INFO     | models.classification.factory:create_classifier:126 - Created titanic classifier with mlx-community/answerdotai-ModernBERT-base-4bit
âœ“ Created New Architecture MLX Embeddings ModernBERT model
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[32m2025-07-17 09:21:02[0m | [1mINFO    [0m | [36mtraining.memory_manager[0m:[36m__init__[0m:[36m82[0m - [1mMemory Manager initialized:
  Apple Silicon: True
  Unified Memory: 32.00 GB
  Optimal Usage: 64.0%
  Target Memory: 20.48 GB[0m
[32m2025-07-17 09:21:02[0m | [1mINFO    [0m | [36mtraining.performance_profiler[0m:[36m__init__[0m:[36m101[0m - [1mPerformance Profiler initialized:
  Apple Silicon: True
  Neural Engine: True
  Thermal Monitoring: True
  Power Monitoring: True[0m
2025/07/17 09:21:02 INFO mlflow.store.db.utils: Creating initial MLflow database tables...
2025/07/17 09:21:02 INFO mlflow.store.db.utils: Updating database tables
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
[32m2025-07-17 09:21:02[0m | [1mINFO    [0m | [36mutils.mlflow_central[0m:[36minitialize[0m:[36m83[0m - [1mMLflow initialized with central configuration:
  Tracking URI: sqlite:///mlruns/mlflow.db
  Artifact Root: ./mlruns/artifacts
  Experiment: mlx_unified[0m
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[32m2025-07-17 09:21:03[0m | [33m[1mWARNING [0m | [36mtraining.monitoring[0m:[36m_log_config_params[0m:[36m242[0m - [33m[1mFailed to log config parameters: 'MemoryConfig' object has no attribute 'gradient_accumulation_steps'[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36m_initialize_mlflow[0m:[36m193[0m - [1mStarted MLflow run: c4f44f565a22407eae9c4ac6d1a13720[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36m__init__[0m:[36m597[0m - [1mInitialized comprehensive monitoring system[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36m_apply_apple_silicon_optimizations[0m:[36m1067[0m - [1mApplying Apple Silicon optimizations...[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36m__init__[0m:[36m146[0m - [1mInitialized Production MLX Trainer:
  Model: TitanicClassifier
  Optimization Level: auto
  Batch Size: 16 (effective: 16)
  Learning Rate: 2e-05
  Epochs: 3
  Apple Silicon: True
  MLflow Enabled: True
  Rich Console: False
  Output Dir: output/run_20250717_092101[0m

Starting training...

[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__enter__[0m:[36m128[0m - [1m============================================================[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__enter__[0m:[36m129[0m - [1mStarting experiment: mlx_unified[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__enter__[0m:[36m130[0m - [1mStart time: 2025-07-17 09:21:03.091442[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__enter__[0m:[36m131[0m - [1m============================================================[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m99[0m - [1mHyperparameters:[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  epochs: 3[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  batch_size: 16[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  learning_rate: 2e-05[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  warmup_steps: 16[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  max_steps: None[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  model_name: answerdotai/ModernBERT-base[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  model_type: modernbert[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  max_length: 256[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  num_labels: None[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  train_path: data/titanic/train.csv[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  val_path: data/titanic/val.csv[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  test_path: None[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  target_column: None[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  optimizer: adamw[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  lr_schedule: cosine_warmup[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  loss_function: cross_entropy[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  optimization_level: auto[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  memory: {'enable_memory_profiling': True, 'memory_limit_gb': None, 'dynamic_batch_sizing': True, 'min_batch_size': 4, 'max_batch_size': 128, 'memory_check_interval': 100, 'unified_memory_fraction': 0.8, 'enable_memory_pool': True, 'force_garbage_collection': True, 'gc_interval': 500}[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  mlx_optimization: {'enable_lazy_evaluation': True, 'eval_frequency': 10, 'enable_gradient_checkpointing': False, 'gradient_accumulation_steps': 1, 'max_grad_norm': 1.0, 'device_placement_strategy': 'auto', 'enable_multi_device': False, 'mixed_precision': False, 'precision_dtype': 'float32', 'enable_jit': True, 'optimize_memory_layout': True}[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  monitoring: {'enable_mlflow': True, 'experiment_name': 'mlx_unified', 'run_name': 'base_20250717_092101', 'tracking_uri': None, 'log_level': 'INFO', 'log_to_file': True, 'log_file_path': 'output/run_20250717_092101/training.log', 'enable_rich_console': False, 'log_frequency': 10, 'eval_frequency': 500, 'save_frequency': 1000, 'enable_progress_bar': True, 'progress_bar_style': 'rich', 'track_gradients': False, 'track_weights': False, 'track_memory': True, 'track_performance': True}[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  checkpoint: {'enable_checkpointing': True, 'checkpoint_dir': 'output/run_20250717_092101/output/run_20250717_092101/checkpoints', 'checkpoint_frequency': 100, 'save_optimizer_state': True, 'save_scheduler_state': True, 'save_random_state': True, 'save_model_weights': True, 'max_checkpoints_to_keep': 5, 'save_best_model': True, 'best_model_metric': 'val_accuracy', 'best_model_mode': 'max', 'auto_resume': True, 'resume_from_checkpoint': None, 'use_safetensors': True, 'compress_checkpoints': False}[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  evaluation: {'eval_during_training': True, 'eval_steps': 100, 'eval_strategy': 'steps', 'primary_metric': 'accuracy', 'metrics_to_compute': ['accuracy', 'precision', 'recall', 'f1', 'auc'], 'enable_early_stopping': True, 'early_stopping_patience': 3, 'early_stopping_threshold': 0.001, 'early_stopping_metric': 'val_loss', 'early_stopping_mode': 'min', 'validation_split': 0.2, 'validation_batch_size': None, 'test_at_end': True, 'generate_predictions': True, 'save_predictions': True}[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  advanced: {'label_smoothing': 0.0, 'dropout_rate': 0.1, 'weight_decay': 0.01, 'enable_augmentation': True, 'augmentation_probability': 0.5, 'enable_curriculum_learning': False, 'curriculum_strategy': 'difficulty', 'curriculum_pace': 0.1, 'enable_ensembling': False, 'ensemble_size': 1, 'ensemble_strategy': 'averaging', 'enable_distillation': False, 'teacher_model_path': None, 'distillation_temperature': 3.0, 'distillation_alpha': 0.5, 'enable_hpo': False, 'hpo_backend': 'optuna', 'hpo_trials': 50, 'hpo_metric': 'val_accuracy'}[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  seed: 42[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  deterministic: True[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  output_dir: output/run_20250717_092101[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  experiment_name: mlx_unified[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  run_name: base_20250717_092101[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mtraining.config[0m:[36m_auto_configure_optimization[0m:[36m307[0m - [1mAuto-configuring optimization level...[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mtraining.config[0m:[36mupdate_from_dataset[0m:[36m497[0m - [1mAuto-configured optimization level: OptimizationLevel.DEVELOPMENT[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mtrain[0m:[36m652[0m - [1mTraining Configuration:
  Steps per epoch: 56
  Total steps: 168
  Effective batch size: 16
  Warmup steps: 16[0m
[32m2025-07-17 09:21:03[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36mstart_training[0m:[36m607[0m - [1mStarted training monitoring: 3 epochs, 56 steps/epoch[0m
  Epoch 1/3 (Loss: nan, LR: 1.68e-05) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00
[32m2025-07-17 09:21:28[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mtrain[0m:[36m688[0m - [1mEpoch 1/3 completed: Loss=nan, Time=25.6s[0m
[32m2025-07-17 09:21:48[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m476[0m - [1mStarting validation evaluation[0m
â § Epoch 2/3 (Loss: nan, LR: 8.35e-06) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸        79% 0:00:06
[32m2025-07-17 09:21:48[0m | [31m[1mERROR   [0m | [36mtraining.mlx_trainer[0m:[36mtrain[0m:[36m736[0m - [31m[1mTraining failed: Only one live display may be active at once[0m
[32m2025-07-17 09:21:48[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36mend_run[0m:[36m287[0m - [1mEnded MLflow run: c4f44f565a22407eae9c4ac6d1a13720 with status: FAILED[0m
[32m2025-07-17 09:21:48[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36mend_training[0m:[36m802[0m - [1mTraining monitoring ended with status: FAILED[0m
[32m2025-07-17 09:21:48[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36mend_training[0m:[36m803[0m - [1mTotal time: 45.4s, Steps: 100[0m
[32m2025-07-17 09:21:48[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m142[0m - [1m============================================================[0m
[32m2025-07-17 09:21:48[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m143[0m - [1mExperiment completed: mlx_unified[0m
[32m2025-07-17 09:21:48[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m144[0m - [1mEnd time: 2025-07-17 09:21:48.552694[0m
[32m2025-07-17 09:21:48[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m145[0m - [1mDuration: 0:00:45.461252[0m
[32m2025-07-17 09:21:48[0m | [31m[1mERROR   [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m148[0m - [31m[1mExperiment failed with error: Only one live display may be active at once[0m
[32m2025-07-17 09:21:48[0m | [31m[1mERROR   [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m149[0m - [31m[1mException details:[0m
[33m[1mTraceback (most recent call last):[0m

  File "[32m/Users/parkergabel/PycharmProjects/bert-playground/[0m[32m[1mmlx_bert_cli.py[0m", line [33m668[0m, in [35m<module>[0m
    [1mapp[0m[1m([0m[1m)[0m
    [36mâ”” [0m[36m[1m<typer.main.Typer object at 0x1073050f0>[0m

  File "/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/typer/main.py", line 324, in __call__
    return get_command(self)(*args, **kwargs)
           â”‚           â”‚      â”‚       â”” {}
           â”‚           â”‚      â”” ()
           â”‚           â”” <typer.main.Typer object at 0x1073050f0>
           â”” <function get_command at 0x1073dda20>
  File "/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/click/core.py", line 1442, in __call__
    return self.main(*args, **kwargs)
           â”‚    â”‚     â”‚       â”” {}
           â”‚    â”‚     â”” ()
           â”‚    â”” <function TyperGroup.main at 0x1073dc0d0>
           â”” <TyperGroup mlx-bert>
  File "/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/typer/core.py", line 757, in main
    return _main(
           â”” <function _main at 0x107347400>
  File "/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/typer/core.py", line 195, in _main
    rv = self.invoke(ctx)
         â”‚    â”‚      â”” <click.core.Context object at 0x12fb898a0>
         â”‚    â”” <function Group.invoke at 0x101d37640>
         â”” <TyperGroup mlx-bert>
  File "/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/click/core.py", line 1830, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
           â”‚               â”‚       â”‚       â”‚      â”” <click.core.Context object at 0x1304e0fa0>
           â”‚               â”‚       â”‚       â”” <function Command.invoke at 0x101d36b90>
           â”‚               â”‚       â”” <TyperCommand train>
           â”‚               â”” <click.core.Context object at 0x1304e0fa0>
           â”” <function Group.invoke.<locals>._process_result at 0x1305c2cb0>
  File "/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/click/core.py", line 1226, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           â”‚   â”‚      â”‚    â”‚           â”‚   â”” {'train_path': 'data/titanic/train.csv', 'val_path': 'data/titanic/val.csv', 'num_epochs': 3, 'batch_size': 16, 'use_mlx_embe...
           â”‚   â”‚      â”‚    â”‚           â”” <click.core.Context object at 0x1304e0fa0>
           â”‚   â”‚      â”‚    â”” <function train at 0x10854a950>
           â”‚   â”‚      â”” <TyperCommand train>
           â”‚   â”” <function Context.invoke at 0x101d35f30>
           â”” <click.core.Context object at 0x1304e0fa0>
  File "/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/click/core.py", line 794, in invoke
    return callback(*args, **kwargs)
           â”‚         â”‚       â”” {'train_path': 'data/titanic/train.csv', 'val_path': 'data/titanic/val.csv', 'num_epochs': 3, 'batch_size': 16, 'use_mlx_embe...
           â”‚         â”” ()
           â”” <function train at 0x10854a950>
  File "/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/typer/main.py", line 699, in wrapper
    return callback(**use_params)
           â”‚          â”” {'train_path': PosixPath('data/titanic/train.csv'), 'val_path': PosixPath('data/titanic/val.csv'), 'output_dir': PosixPath('o...
           â”” <function train at 0x10d184b80>

  File "[32m/Users/parkergabel/PycharmProjects/bert-playground/[0m[32m[1mmlx_bert_cli.py[0m", line [33m345[0m, in [35mtrain[0m
    [1mresults[0m [35m[1m=[0m [1mtrainer[0m[35m[1m.[0m[1mtrain[0m[1m([0m
    [36m          â”‚       â”” [0m[36m[1m<function MLXTrainer.train at 0x1305c1fc0>[0m
    [36m          â”” [0m[36m[1m<training.mlx_trainer.MLXTrainer object at 0x12fa509d0>[0m

> File "[32m/Users/parkergabel/PycharmProjects/bert-playground/training/[0m[32m[1mmlx_trainer.py[0m", line [33m684[0m, in [35mtrain[0m
    [1mepoch_metrics[0m [35m[1m=[0m [1mself[0m[35m[1m.[0m[1m_train_epoch[0m[1m([0m[1mtrain_loader[0m[1m,[0m [1mval_loader[0m[1m,[0m [1mhistory[0m[1m)[0m
    [36m                â”‚    â”‚            â”‚             â”‚           â”” [0m[36m[1m{'train_loss': [nan], 'validation_metrics': [], 'learning_rates': [1.25e-06, 2.5e-06, 3.7500000000000005e-06, 5e-06, 6.25e-06...[0m
    [36m                â”‚    â”‚            â”‚             â”” [0m[36m[1m<data.mlx_dataloader.KaggleDataLoader object at 0x11a2661d0>[0m
    [36m                â”‚    â”‚            â”” [0m[36m[1m<data.mlx_dataloader.KaggleDataLoader object at 0x1304e2320>[0m
    [36m                â”‚    â”” [0m[36m[1m<function MLXTrainer._train_epoch at 0x1305c2050>[0m
    [36m                â”” [0m[36m[1m<training.mlx_trainer.MLXTrainer object at 0x12fa509d0>[0m

  File "[32m/Users/parkergabel/PycharmProjects/bert-playground/training/[0m[32m[1mmlx_trainer.py[0m", line [33m821[0m, in [35m_train_epoch[0m
    [1mval_metrics[0m [35m[1m=[0m [1mself[0m[35m[1m.[0m[1mevaluate[0m[1m([0m[1mval_loader[0m[1m,[0m [36m"validation"[0m[1m)[0m
    [36m              â”‚    â”‚        â”” [0m[36m[1m<data.mlx_dataloader.KaggleDataLoader object at 0x11a2661d0>[0m
    [36m              â”‚    â”” [0m[36m[1m<function MLXTrainer.evaluate at 0x1305c1ea0>[0m
    [36m              â”” [0m[36m[1m<training.mlx_trainer.MLXTrainer object at 0x12fa509d0>[0m

  File "[32m/Users/parkergabel/PycharmProjects/bert-playground/training/[0m[32m[1mmlx_trainer.py[0m", line [33m485[0m, in [35mevaluate[0m
    [35m[1mwith[0m [1mProgress[0m[1m([0m
    [36m     â”” [0m[36m[1m<class 'rich.progress.Progress'>[0m

  File "/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/rich/progress.py", line 1182, in __enter__
    self.start()
    â”‚    â”” <function Progress.start at 0x1083d4940>
    â”” <rich.progress.Progress object at 0x1416029b0>
  File "/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/rich/progress.py", line 1173, in start
    self.live.start(refresh=True)
    â”‚    â”‚    â”” <function Live.start at 0x1074b4b80>
    â”‚    â”” <rich.live.Live object at 0x141603220>
    â”” <rich.progress.Progress object at 0x1416029b0>
  File "/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/rich/live.py", line 113, in start
    self.console.set_live(self)
    â”‚    â”‚       â”‚        â”” <rich.live.Live object at 0x141603220>
    â”‚    â”‚       â”” <function Console.set_live at 0x106feff40>
    â”‚    â”” <console width=80 None>
    â”” <rich.live.Live object at 0x141603220>
  File "/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/rich/console.py", line 837, in set_live
    raise errors.LiveError("Only one live display may be active at once")
          â”‚      â”” <class 'rich.errors.LiveError'>
          â”” <module 'rich.errors' from '/Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site-packages/rich/errors...

[31m[1mrich.errors.LiveError[0m:[1m Only one live display may be active at once[0m
[32m2025-07-17 09:21:48[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m153[0m - [1m============================================================[0m
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Traceback (most recent call last) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ /Users/parkergabel/PycharmProjects/bert-playground/mlx_bert_cli.py:345 in    â”‚
â”‚ train                                                                        â”‚
â”‚                                                                              â”‚
â”‚   342 â”‚   console.print("\n[bold green]Starting training...[/bold green]\n") â”‚
â”‚   343 â”‚                                                                      â”‚
â”‚   344 â”‚   start_time = time.time()                                           â”‚
â”‚ â± 345 â”‚   results = trainer.train(                                           â”‚
â”‚   346 â”‚   â”‚   train_loader=train_loader,                                     â”‚
â”‚   347 â”‚   â”‚   val_loader=val_loader,                                         â”‚
â”‚   348 â”‚   â”‚   resume_from_checkpoint=resume_from,                            â”‚
â”‚                                                                              â”‚
â”‚ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ locals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚
â”‚ â”‚                 augment = True                                           â”‚ â”‚
â”‚ â”‚              batch_size = 16                                             â”‚ â”‚
â”‚ â”‚       batch_size_config = 16                                             â”‚ â”‚
â”‚ â”‚        cnn_kernel_sizes = '2,3,4,5'                                      â”‚ â”‚
â”‚ â”‚         cnn_num_filters = 128                                            â”‚ â”‚
â”‚ â”‚                  config = None                                           â”‚ â”‚
â”‚ â”‚        config_overrides = {}                                             â”‚ â”‚
â”‚ â”‚            config_table = <rich.table.Table object at 0x130562cb0>       â”‚ â”‚
â”‚ â”‚          disable_mlflow = False                                          â”‚ â”‚
â”‚ â”‚ early_stopping_patience = 3                                              â”‚ â”‚
â”‚ â”‚ enable_dynamic_batching = True                                           â”‚ â”‚
â”‚ â”‚         eval_batch_size = 32                                             â”‚ â”‚
â”‚ â”‚              eval_steps = 100                                            â”‚ â”‚
â”‚ â”‚         experiment_name = 'mlx_unified'                                  â”‚ â”‚
â”‚ â”‚                       f = <_io.TextIOWrapper                             â”‚ â”‚
â”‚ â”‚                           name='output/run_20250717_092101/training_conâ€¦ â”‚ â”‚
â”‚ â”‚                           mode='w' encoding='UTF-8'>                     â”‚ â”‚
â”‚ â”‚             full_config = {                                              â”‚ â”‚
â”‚ â”‚                           â”‚   'model':                                   â”‚ â”‚
â”‚ â”‚                           'mlx-community/answerdotai-ModernBERT-base-4bâ€¦ â”‚ â”‚
â”‚ â”‚                           â”‚   'model_type': 'base',                      â”‚ â”‚
â”‚ â”‚                           â”‚   'use_mlx_embeddings': True,                â”‚ â”‚
â”‚ â”‚                           â”‚   'tokenizer_backend': 'auto',               â”‚ â”‚
â”‚ â”‚                           â”‚   'train_path': 'data/titanic/train.csv',    â”‚ â”‚
â”‚ â”‚                           â”‚   'val_path': 'data/titanic/val.csv',        â”‚ â”‚
â”‚ â”‚                           â”‚   'timestamp': '20250717_092101',            â”‚ â”‚
â”‚ â”‚                           â”‚   'learning_rate': 2e-05,                    â”‚ â”‚
â”‚ â”‚                           â”‚   'epochs': 3,                               â”‚ â”‚
â”‚ â”‚                           â”‚   'batch_size': 16,                          â”‚ â”‚
â”‚ â”‚                           â”‚   ... +9                                     â”‚ â”‚
â”‚ â”‚                           }                                              â”‚ â”‚
â”‚ â”‚   gradient_accumulation = 1                                              â”‚ â”‚
â”‚ â”‚           gradient_clip = 1.0                                            â”‚ â”‚
â”‚ â”‚         label_smoothing = 0.0                                            â”‚ â”‚
â”‚ â”‚           learning_rate = 2e-05                                          â”‚ â”‚
â”‚ â”‚          max_batch_size = 64                                             â”‚ â”‚
â”‚ â”‚   max_batch_size_config = 64                                             â”‚ â”‚
â”‚ â”‚              max_length = 256                                            â”‚ â”‚
â”‚ â”‚                   model = TitanicClassifier(                             â”‚ â”‚
â”‚ â”‚                             (embedding_model): EmbeddingModel(           â”‚ â”‚
â”‚ â”‚                           â”‚   (embedding_model): Model(                  â”‚ â”‚
â”‚ â”‚                           â”‚     (model): ModernBertModel(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (embeddings): ModernBertEmbeddings(    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (tok_embeddings):                    â”‚ â”‚
â”‚ â”‚                           QuantizedEmbedding(50368, 768, group_size=64,  â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (norm): LayerNorm(768, eps=1e-05,    â”‚ â”‚
â”‚ â”‚                           affine=True)                                   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (drop): Dropout(p=0.0)               â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.0): ModernBertEncoderLayer(    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): Identity()              â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.1): ModernBertEncoderLayer(    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.2): ModernBertEncoderLayer(    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.3): ModernBertEncoderLayer(    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.4): ModernBertEncoderLayer(    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.5): ModernBertEncoderLayer(    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.6): ModernBertEncoderLayer(    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.7): ModernBertEncoderLayer(    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.8): ModernBertEncoderLayer(    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.9): ModernBertEncoderLayer(    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.10): ModernBertEncoderLayer(   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.11): ModernBertEncoderLayer(   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.12): ModernBertEncoderLayer(   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.13): ModernBertEncoderLayer(   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.14): ModernBertEncoderLayer(   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.15): ModernBertEncoderLayer(   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.16): ModernBertEncoderLayer(   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.17): ModernBertEncoderLayer(   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.18): ModernBertEncoderLayer(   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.19): ModernBertEncoderLayer(   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.20): ModernBertEncoderLayer(   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (layers.21): ModernBertEncoderLayer(   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn_norm): LayerNorm(768,          â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (attn): ModernBertAttention(         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wqkv):                            â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (rotary_emb): RoPE(64,             â”‚ â”‚
â”‚ â”‚                           traditional=False)                             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (out_drop): Identity()             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp): ModernBertMLP(                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wi):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=2304, bias=False, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (act): GELU()                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (drop): Dropout(p=0.0)             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   (Wo):                              â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=1152,               â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     )                                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚     (mlp_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   )                                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (final_norm): LayerNorm(768,           â”‚ â”‚
â”‚ â”‚                           eps=1e-05, affine=True)                        â”‚ â”‚
â”‚ â”‚                           â”‚     )                                        â”‚ â”‚
â”‚ â”‚                           â”‚     (head): ModernBertPredictionHead(        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (dense):                               â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=768, bias=False, group_size=64,    â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (act): GELU()                          â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   (norm): LayerNorm(768, eps=1e-05,      â”‚ â”‚
â”‚ â”‚                           affine=True)                                   â”‚ â”‚
â”‚ â”‚                           â”‚     )                                        â”‚ â”‚
â”‚ â”‚                           â”‚     (decoder):                               â”‚ â”‚
â”‚ â”‚                           QuantizedLinear(input_dims=768,                â”‚ â”‚
â”‚ â”‚                           output_dims=50368, bias=True, group_size=64,   â”‚ â”‚
â”‚ â”‚                           bits=4)                                        â”‚ â”‚
â”‚ â”‚                           â”‚   )                                          â”‚ â”‚
â”‚ â”‚                             )                                            â”‚ â”‚
â”‚ â”‚                             (classification_head):                       â”‚ â”‚
â”‚ â”‚                           BinaryClassificationHead(                      â”‚ â”‚
â”‚ â”‚                           â”‚   (classifier): Sequential(                  â”‚ â”‚
â”‚ â”‚                           â”‚     (layers.0):                              â”‚ â”‚
â”‚ â”‚                           Dropout(p=0.09999999999999998)                 â”‚ â”‚
â”‚ â”‚                           â”‚     (layers.1): Linear(input_dims=768,       â”‚ â”‚
â”‚ â”‚                           output_dims=2, bias=True)                      â”‚ â”‚
â”‚ â”‚                           â”‚   )                                          â”‚ â”‚
â”‚ â”‚                             )                                            â”‚ â”‚
â”‚ â”‚                           )                                              â”‚ â”‚
â”‚ â”‚              model_desc = 'New Architecture MLX Embeddings ModernBERT'   â”‚ â”‚
â”‚ â”‚              model_name = 'mlx-community/answerdotai-ModernBERT-base-4bâ€¦ â”‚ â”‚
â”‚ â”‚              model_type = 'base'                                         â”‚ â”‚
â”‚ â”‚              num_epochs = 3                                              â”‚ â”‚
â”‚ â”‚             num_workers = 4                                              â”‚ â”‚
â”‚ â”‚               optimizer = <mlx.optimizers.optimizers.AdamW object at     â”‚ â”‚
â”‚ â”‚                           0x11a3aebc0>                                   â”‚ â”‚
â”‚ â”‚              output_dir = PosixPath('output')                            â”‚ â”‚
â”‚ â”‚           prefetch_size = 4                                              â”‚ â”‚
â”‚ â”‚             resume_from = None                                           â”‚ â”‚
â”‚ â”‚                 run_dir = PosixPath('output/run_20250717_092101')        â”‚ â”‚
â”‚ â”‚                run_name = None                                           â”‚ â”‚
â”‚ â”‚              save_steps = 100                                            â”‚ â”‚
â”‚ â”‚              start_time = 1752769263.09135                               â”‚ â”‚
â”‚ â”‚               timestamp = '20250717_092101'                              â”‚ â”‚
â”‚ â”‚       tokenizer_backend = 'auto'                                         â”‚ â”‚
â”‚ â”‚            train_loader = <data.mlx_dataloader.KaggleDataLoader object   â”‚ â”‚
â”‚ â”‚                           at 0x1304e2320>                                â”‚ â”‚
â”‚ â”‚              train_path = PosixPath('data/titanic/train.csv')            â”‚ â”‚
â”‚ â”‚           train_samples = 896                                            â”‚ â”‚
â”‚ â”‚                 trainer = <training.mlx_trainer.MLXTrainer object at     â”‚ â”‚
â”‚ â”‚                           0x12fa509d0>                                   â”‚ â”‚
â”‚ â”‚         training_config = TrainingConfig(                                â”‚ â”‚
â”‚ â”‚                           â”‚   epochs=3,                                  â”‚ â”‚
â”‚ â”‚                           â”‚   batch_size=16,                             â”‚ â”‚
â”‚ â”‚                           â”‚   learning_rate=2e-05,                       â”‚ â”‚
â”‚ â”‚                           â”‚   warmup_steps=16,                           â”‚ â”‚
â”‚ â”‚                           â”‚   max_steps=None,                            â”‚ â”‚
â”‚ â”‚                           â”‚   model_name='answerdotai/ModernBERT-base',  â”‚ â”‚
â”‚ â”‚                           â”‚   model_type='modernbert',                   â”‚ â”‚
â”‚ â”‚                           â”‚   max_length=256,                            â”‚ â”‚
â”‚ â”‚                           â”‚   num_labels=1,                              â”‚ â”‚
â”‚ â”‚                           â”‚   train_path='data/titanic/train.csv',       â”‚ â”‚
â”‚ â”‚                           â”‚   val_path='data/titanic/val.csv',           â”‚ â”‚
â”‚ â”‚                           â”‚   test_path=None,                            â”‚ â”‚
â”‚ â”‚                           â”‚   target_column=None,                        â”‚ â”‚
â”‚ â”‚                           â”‚   optimizer=<OptimizerType.ADAMW: 'adamw'>,  â”‚ â”‚
â”‚ â”‚                           â”‚                                              â”‚ â”‚
â”‚ â”‚                           lr_schedule=<LearningRateSchedule.COSINE_WARMâ€¦ â”‚ â”‚
â”‚ â”‚                           'cosine_warmup'>,                              â”‚ â”‚
â”‚ â”‚                           â”‚   loss_function=<LossFunction.CROSS_ENTROPY: â”‚ â”‚
â”‚ â”‚                           'cross_entropy'>,                              â”‚ â”‚
â”‚ â”‚                           â”‚                                              â”‚ â”‚
â”‚ â”‚                           optimization_level=<OptimizationLevel.DEVELOPâ€¦ â”‚ â”‚
â”‚ â”‚                           'development'>,                                â”‚ â”‚
â”‚ â”‚                           â”‚   memory=MemoryConfig(                       â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_memory_profiling=False,         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   memory_limit_gb=None,                  â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   dynamic_batch_sizing=False,            â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   min_batch_size=4,                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   max_batch_size=128,                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   memory_check_interval=100,             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   unified_memory_fraction=0.8,           â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_memory_pool=True,               â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   force_garbage_collection=True,         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   gc_interval=500                        â”‚ â”‚
â”‚ â”‚                           â”‚   ),                                         â”‚ â”‚
â”‚ â”‚                           â”‚   mlx_optimization=MLXOptimizationConfig(    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_lazy_evaluation=True,           â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   eval_frequency=5,                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_gradient_checkpointing=False,   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   gradient_accumulation_steps=1,         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   max_grad_norm=1.0,                     â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   device_placement_strategy='auto',      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_multi_device=False,             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   mixed_precision=False,                 â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   precision_dtype='float32',             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_jit=True,                       â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   optimize_memory_layout=True            â”‚ â”‚
â”‚ â”‚                           â”‚   ),                                         â”‚ â”‚
â”‚ â”‚                           â”‚   monitoring=MonitoringConfig(               â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_mlflow=True,                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   experiment_name='mlx_unified',         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   run_name='base_20250717_092101',       â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   tracking_uri=None,                     â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   log_level='INFO',                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   log_to_file=True,                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚                                          â”‚ â”‚
â”‚ â”‚                           log_file_path='output/run_20250717_092101/traâ€¦ â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_rich_console=False,             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   log_frequency=5,                       â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   eval_frequency=500,                    â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   save_frequency=1000,                   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_progress_bar=True,              â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   progress_bar_style='rich',             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   track_gradients=False,                 â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   track_weights=False,                   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   track_memory=True,                     â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   track_performance=True                 â”‚ â”‚
â”‚ â”‚                           â”‚   ),                                         â”‚ â”‚
â”‚ â”‚                           â”‚   checkpoint=CheckpointConfig(               â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_checkpointing=True,             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚                                          â”‚ â”‚
â”‚ â”‚                           checkpoint_dir='output/run_20250717_092101/ouâ€¦ â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   checkpoint_frequency=100,              â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   save_optimizer_state=True,             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   save_scheduler_state=True,             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   save_random_state=True,                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   save_model_weights=True,               â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   max_checkpoints_to_keep=5,             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   save_best_model=True,                  â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   best_model_metric='val_accuracy',      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   best_model_mode='max',                 â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   auto_resume=True,                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   resume_from_checkpoint=None,           â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   use_safetensors=True,                  â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   compress_checkpoints=False             â”‚ â”‚
â”‚ â”‚                           â”‚   ),                                         â”‚ â”‚
â”‚ â”‚                           â”‚   evaluation=EvaluationConfig(               â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   eval_during_training=True,             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   eval_steps=100,                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   eval_strategy='steps',                 â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   primary_metric='accuracy',             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   metrics_to_compute=[                   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   'accuracy',                        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   'precision',                       â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   'recall',                          â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   'f1',                              â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   â”‚   'auc'                              â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   ],                                     â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_early_stopping=True,            â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   early_stopping_patience=3,             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   early_stopping_threshold=0.001,        â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   early_stopping_metric='val_loss',      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   early_stopping_mode='min',             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   validation_split=0.2,                  â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   validation_batch_size=None,            â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   test_at_end=True,                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   generate_predictions=True,             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   save_predictions=True                  â”‚ â”‚
â”‚ â”‚                           â”‚   ),                                         â”‚ â”‚
â”‚ â”‚                           â”‚   advanced=AdvancedFeatures(                 â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   label_smoothing=0.0,                   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   dropout_rate=0.1,                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   weight_decay=0.01,                     â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_augmentation=True,              â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   augmentation_probability=0.5,          â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_curriculum_learning=False,      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   curriculum_strategy='difficulty',      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   curriculum_pace=0.1,                   â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_ensembling=False,               â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   ensemble_size=1,                       â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   ensemble_strategy='averaging',         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_distillation=False,             â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   teacher_model_path=None,               â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   distillation_temperature=3.0,          â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   distillation_alpha=0.5,                â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   enable_hpo=False,                      â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   hpo_backend='optuna',                  â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   hpo_trials=50,                         â”‚ â”‚
â”‚ â”‚                           â”‚   â”‚   hpo_metric='val_accuracy'              â”‚ â”‚
â”‚ â”‚                           â”‚   ),                                         â”‚ â”‚
â”‚ â”‚                           â”‚   seed=42,                                   â”‚ â”‚
â”‚ â”‚                           â”‚   deterministic=True,                        â”‚ â”‚
â”‚ â”‚                           â”‚   output_dir='output/run_20250717_092101',   â”‚ â”‚
â”‚ â”‚                           â”‚   experiment_name='mlx_unified',             â”‚ â”‚
â”‚ â”‚                           â”‚   run_name='base_20250717_092101'            â”‚ â”‚
â”‚ â”‚                           )                                              â”‚ â”‚
â”‚ â”‚        use_dilated_conv = True                                           â”‚ â”‚
â”‚ â”‚      use_mlx_embeddings = True                                           â”‚ â”‚
â”‚ â”‚              val_loader = <data.mlx_dataloader.KaggleDataLoader object   â”‚ â”‚
â”‚ â”‚                           at 0x11a2661d0>                                â”‚ â”‚
â”‚ â”‚                val_path = PosixPath('data/titanic/val.csv')              â”‚ â”‚
â”‚ â”‚             val_samples = 192                                            â”‚ â”‚
â”‚ â”‚            warmup_ratio = 0.1                                            â”‚ â”‚
â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚
â”‚                                                                              â”‚
â”‚ /Users/parkergabel/PycharmProjects/bert-playground/training/mlx_trainer.py:6 â”‚
â”‚ 84 in train                                                                  â”‚
â”‚                                                                              â”‚
â”‚    681 â”‚   â”‚   â”‚   â”‚   â”‚   if self.config.memory.dynamic_batch_sizing:       â”‚
â”‚    682 â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   self.adjust_batch_size_dynamically()          â”‚
â”‚    683 â”‚   â”‚   â”‚   â”‚   â”‚                                                     â”‚
â”‚ â±  684 â”‚   â”‚   â”‚   â”‚   â”‚   epoch_metrics = self._train_epoch(train_loader, v â”‚
â”‚    685 â”‚   â”‚   â”‚   â”‚   â”‚                                                     â”‚
â”‚    686 â”‚   â”‚   â”‚   â”‚   â”‚   # Log epoch summary                               â”‚
â”‚    687 â”‚   â”‚   â”‚   â”‚   â”‚   epoch_time = time.time() - epoch_start_time       â”‚
â”‚                                                                              â”‚
â”‚ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ locals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚
â”‚ â”‚                  epoch = 1                                               â”‚ â”‚
â”‚ â”‚          epoch_metrics = {                                               â”‚ â”‚
â”‚ â”‚                          â”‚   'avg_loss': nan,                            â”‚ â”‚
â”‚ â”‚                          â”‚   'avg_step_time':                            â”‚ â”‚
â”‚ â”‚                          np.float64(0.45231832351003376),                â”‚ â”‚
â”‚ â”‚                          â”‚   'throughput': np.float64(35.37331823269608) â”‚ â”‚
â”‚ â”‚                          }                                               â”‚ â”‚
â”‚ â”‚       epoch_start_time = 1752769288.728866                               â”‚ â”‚
â”‚ â”‚             epoch_time = 25.63435959815979                               â”‚ â”‚
â”‚ â”‚        experiment_name = 'mlx_unified'                                   â”‚ â”‚
â”‚ â”‚                history = {                                               â”‚ â”‚
â”‚ â”‚                          â”‚   'train_loss': [nan],                        â”‚ â”‚
â”‚ â”‚                          â”‚   'validation_metrics': [],                   â”‚ â”‚
â”‚ â”‚                          â”‚   'learning_rates': [                         â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   1.25e-06,                               â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   2.5e-06,                                â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   3.7500000000000005e-06,                 â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   5e-06,                                  â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   6.25e-06,                               â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   7.500000000000001e-06,                  â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   8.750000000000001e-06,                  â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   1e-05,                                  â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   1.125e-05,                              â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   1.25e-05,                               â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   ... +90                                 â”‚ â”‚
â”‚ â”‚                          â”‚   ],                                          â”‚ â”‚
â”‚ â”‚                          â”‚   'memory_usage': [                           â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   0.0,                                    â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   0.0,                                    â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   0.0,                                    â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   0.0,                                    â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   0.0,                                    â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   0.0,                                    â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   0.0,                                    â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   0.0,                                    â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   0.0,                                    â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   0.0,                                    â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   ... +90                                 â”‚ â”‚
â”‚ â”‚                          â”‚   ],                                          â”‚ â”‚
â”‚ â”‚                          â”‚   'batch_sizes': [                            â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   16,                                     â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   16,                                     â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   16,                                     â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   16,                                     â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   16,                                     â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   16,                                     â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   16,                                     â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   16,                                     â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   16,                                     â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   16,                                     â”‚ â”‚
â”‚ â”‚                          â”‚   â”‚   ... +90                                 â”‚ â”‚
â”‚ â”‚                          â”‚   ]                                           â”‚ â”‚
â”‚ â”‚                          }                                               â”‚ â”‚
â”‚ â”‚ resume_from_checkpoint = None                                            â”‚ â”‚
â”‚ â”‚                   self = <training.mlx_trainer.MLXTrainer object at      â”‚ â”‚
â”‚ â”‚                          0x12fa509d0>                                    â”‚ â”‚
â”‚ â”‚             start_time = 1752769263.093421                               â”‚ â”‚
â”‚ â”‚        steps_per_epoch = 56                                              â”‚ â”‚
â”‚ â”‚            test_loader = None                                            â”‚ â”‚
â”‚ â”‚           train_loader = <data.mlx_dataloader.KaggleDataLoader object at â”‚ â”‚
â”‚ â”‚                          0x1304e2320>                                    â”‚ â”‚
â”‚ â”‚             val_loader = <data.mlx_dataloader.KaggleDataLoader object at â”‚ â”‚
â”‚ â”‚                          0x11a2661d0>                                    â”‚ â”‚
â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚
â”‚                                                                              â”‚
â”‚ /Users/parkergabel/PycharmProjects/bert-playground/training/mlx_trainer.py:8 â”‚
â”‚ 21 in _train_epoch                                                           â”‚
â”‚                                                                              â”‚
â”‚    818 â”‚   â”‚   â”‚   â”‚   â”‚   val_loader                                        â”‚
â”‚    819 â”‚   â”‚   â”‚   â”‚   â”‚   and self.global_step % self.config.evaluation.eva â”‚
â”‚    820 â”‚   â”‚   â”‚   â”‚   ):                                                    â”‚
â”‚ â±  821 â”‚   â”‚   â”‚   â”‚   â”‚   val_metrics = self.evaluate(val_loader, "validati â”‚
â”‚    822 â”‚   â”‚   â”‚   â”‚   â”‚   history["validation_metrics"].append(val_metrics) â”‚
â”‚    823 â”‚   â”‚   â”‚   â”‚   â”‚                                                     â”‚
â”‚    824 â”‚   â”‚   â”‚   â”‚   â”‚   # Check for best model                            â”‚
â”‚                                                                              â”‚
â”‚ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ locals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚
â”‚ â”‚   _batch_idx = 43                                                        â”‚ â”‚
â”‚ â”‚        batch = {                                                         â”‚ â”‚
â”‚ â”‚                â”‚   'input_ids': array([[50281, 49, 2437, ..., 50283,     â”‚ â”‚
â”‚ â”‚                50283, 50283],                                            â”‚ â”‚
â”‚ â”‚                â”‚      [50281, 49, 2437, ..., 50283, 50283, 50283],       â”‚ â”‚
â”‚ â”‚                â”‚      [50281, 49, 2437, ..., 50283, 50283, 50283],       â”‚ â”‚
â”‚ â”‚                â”‚      ...,                                               â”‚ â”‚
â”‚ â”‚                â”‚      [50281, 49, 2437, ..., 50283, 50283, 50283],       â”‚ â”‚
â”‚ â”‚                â”‚      [50281, 49, 2437, ..., 50283, 50283, 50283],       â”‚ â”‚
â”‚ â”‚                â”‚      [50281, 49, 2437, ..., 50283, 50283, 50283]],      â”‚ â”‚
â”‚ â”‚                dtype=int32),                                             â”‚ â”‚
â”‚ â”‚                â”‚   'attention_mask': array([[1, 1, 1, ..., 0, 0, 0],     â”‚ â”‚
â”‚ â”‚                â”‚      [1, 1, 1, ..., 0, 0, 0],                           â”‚ â”‚
â”‚ â”‚                â”‚      [1, 1, 1, ..., 0, 0, 0],                           â”‚ â”‚
â”‚ â”‚                â”‚      ...,                                               â”‚ â”‚
â”‚ â”‚                â”‚      [1, 1, 1, ..., 0, 0, 0],                           â”‚ â”‚
â”‚ â”‚                â”‚      [1, 1, 1, ..., 0, 0, 0],                           â”‚ â”‚
â”‚ â”‚                â”‚      [1, 1, 1, ..., 0, 0, 0]], dtype=int32),            â”‚ â”‚
â”‚ â”‚                â”‚   'labels': array([1, 0, 1, ..., 0, 1, 0], dtype=int32) â”‚ â”‚
â”‚ â”‚                }                                                         â”‚ â”‚
â”‚ â”‚   epoch_loss = nan                                                       â”‚ â”‚
â”‚ â”‚      history = {                                                         â”‚ â”‚
â”‚ â”‚                â”‚   'train_loss': [nan],                                  â”‚ â”‚
â”‚ â”‚                â”‚   'validation_metrics': [],                             â”‚ â”‚
â”‚ â”‚                â”‚   'learning_rates': [                                   â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   1.25e-06,                                         â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   2.5e-06,                                          â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   3.7500000000000005e-06,                           â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   5e-06,                                            â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   6.25e-06,                                         â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   7.500000000000001e-06,                            â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   8.750000000000001e-06,                            â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   1e-05,                                            â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   1.125e-05,                                        â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   1.25e-05,                                         â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   ... +90                                           â”‚ â”‚
â”‚ â”‚                â”‚   ],                                                    â”‚ â”‚
â”‚ â”‚                â”‚   'memory_usage': [                                     â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   0.0,                                              â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   0.0,                                              â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   0.0,                                              â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   0.0,                                              â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   0.0,                                              â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   0.0,                                              â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   0.0,                                              â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   0.0,                                              â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   0.0,                                              â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   0.0,                                              â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   ... +90                                           â”‚ â”‚
â”‚ â”‚                â”‚   ],                                                    â”‚ â”‚
â”‚ â”‚                â”‚   'batch_sizes': [                                      â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   16,                                               â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   16,                                               â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   16,                                               â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   16,                                               â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   16,                                               â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   16,                                               â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   16,                                               â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   16,                                               â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   16,                                               â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   16,                                               â”‚ â”‚
â”‚ â”‚                â”‚   â”‚   ... +90                                           â”‚ â”‚
â”‚ â”‚                â”‚   ]                                                     â”‚ â”‚
â”‚ â”‚                }                                                         â”‚ â”‚
â”‚ â”‚         loss = nan                                                       â”‚ â”‚
â”‚ â”‚      metrics = {                                                         â”‚ â”‚
â”‚ â”‚                â”‚   'loss': nan,                                          â”‚ â”‚
â”‚ â”‚                â”‚   'learning_rate': np.float64(8.35405409719266e-06),    â”‚ â”‚
â”‚ â”‚                â”‚   'batch_size': 16,                                     â”‚ â”‚
â”‚ â”‚                â”‚   'memory_usage': 0.0,                                  â”‚ â”‚
â”‚ â”‚                â”‚   'epoch': 1,                                           â”‚ â”‚
â”‚ â”‚                â”‚   'step': 100,                                          â”‚ â”‚
â”‚ â”‚                â”‚   'step_time': 0.44119715690612793,                     â”‚ â”‚
â”‚ â”‚                â”‚   'samples_per_second': 36.26496623912803,              â”‚ â”‚
â”‚ â”‚                â”‚   'tokens_per_second': 9283.831357216775                â”‚ â”‚
â”‚ â”‚                }                                                         â”‚ â”‚
â”‚ â”‚  num_updates = 44                                                        â”‚ â”‚
â”‚ â”‚     progress = <rich.progress.Progress object at 0x14174c820>            â”‚ â”‚
â”‚ â”‚         self = <training.mlx_trainer.MLXTrainer object at 0x12fa509d0>   â”‚ â”‚
â”‚ â”‚   step_start = 1752769308.027209                                         â”‚ â”‚
â”‚ â”‚    step_time = 0.47934985160827637                                       â”‚ â”‚
â”‚ â”‚   step_times = [                                                         â”‚ â”‚
â”‚ â”‚                â”‚   0.4427928924560547,                                   â”‚ â”‚
â”‚ â”‚                â”‚   0.4416377544403076,                                   â”‚ â”‚
â”‚ â”‚                â”‚   0.4420750141143799,                                   â”‚ â”‚
â”‚ â”‚                â”‚   0.48503708839416504,                                  â”‚ â”‚
â”‚ â”‚                â”‚   0.4408700466156006,                                   â”‚ â”‚
â”‚ â”‚                â”‚   0.44133615493774414,                                  â”‚ â”‚
â”‚ â”‚                â”‚   0.44181323051452637,                                  â”‚ â”‚
â”‚ â”‚                â”‚   0.4416658878326416,                                   â”‚ â”‚
â”‚ â”‚                â”‚   0.48347973823547363,                                  â”‚ â”‚
â”‚ â”‚                â”‚   0.4409220218658447,                                   â”‚ â”‚
â”‚ â”‚                â”‚   ... +34                                               â”‚ â”‚
â”‚ â”‚                ]                                                         â”‚ â”‚
â”‚ â”‚ train_loader = <data.mlx_dataloader.KaggleDataLoader object at           â”‚ â”‚
â”‚ â”‚                0x1304e2320>                                              â”‚ â”‚
â”‚ â”‚   train_task = 0                                                         â”‚ â”‚
â”‚ â”‚   val_loader = <data.mlx_dataloader.KaggleDataLoader object at           â”‚ â”‚
â”‚ â”‚                0x11a2661d0>                                              â”‚ â”‚
â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚
â”‚                                                                              â”‚
â”‚ /Users/parkergabel/PycharmProjects/bert-playground/training/mlx_trainer.py:4 â”‚
â”‚ 85 in evaluate                                                               â”‚
â”‚                                                                              â”‚
â”‚    482 â”‚   â”‚   num_batches = 0                                               â”‚
â”‚    483 â”‚   â”‚                                                                 â”‚
â”‚    484 â”‚   â”‚   # Progress tracking                                           â”‚
â”‚ â±  485 â”‚   â”‚   with Progress(                                                â”‚
â”‚    486 â”‚   â”‚   â”‚   SpinnerColumn(),                                          â”‚
â”‚    487 â”‚   â”‚   â”‚   TextColumn("[progress.description]{task.description}"),   â”‚
â”‚    488 â”‚   â”‚   â”‚   BarColumn(),                                              â”‚
â”‚                                                                              â”‚
â”‚ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ locals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚
â”‚ â”‚        all_labels = []                                                   â”‚ â”‚
â”‚ â”‚   all_predictions = []                                                   â”‚ â”‚
â”‚ â”‚ all_probabilities = []                                                   â”‚ â”‚
â”‚ â”‚        dataloader = <data.mlx_dataloader.KaggleDataLoader object at      â”‚ â”‚
â”‚ â”‚                     0x11a2661d0>                                         â”‚ â”‚
â”‚ â”‚       max_batches = None                                                 â”‚ â”‚
â”‚ â”‚       num_batches = 0                                                    â”‚ â”‚
â”‚ â”‚             phase = 'validation'                                         â”‚ â”‚
â”‚ â”‚              self = <training.mlx_trainer.MLXTrainer object at           â”‚ â”‚
â”‚ â”‚                     0x12fa509d0>                                         â”‚ â”‚
â”‚ â”‚        total_loss = 0.0                                                  â”‚ â”‚
â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ â”‚
â”‚                                                                              â”‚
â”‚ /Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site â”‚
â”‚ -packages/rich/progress.py:1182 in __enter__                                 â”‚
â”‚                                                                              â”‚
â”‚   1179 â”‚   â”‚   â”‚   self.console.print()                                      â”‚
â”‚   1180 â”‚                                                                     â”‚
â”‚   1181 â”‚   def __enter__(self) -> Self:                                      â”‚
â”‚ â± 1182 â”‚   â”‚   self.start()                                                  â”‚
â”‚   1183 â”‚   â”‚   return self                                                   â”‚
â”‚   1184 â”‚                                                                     â”‚
â”‚   1185 â”‚   def __exit__(                                                     â”‚
â”‚                                                                              â”‚
â”‚ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ locals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                    â”‚
â”‚ â”‚ self = <rich.progress.Progress object at 0x1416029b0> â”‚                    â”‚
â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯                    â”‚
â”‚                                                                              â”‚
â”‚ /Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site â”‚
â”‚ -packages/rich/progress.py:1173 in start                                     â”‚
â”‚                                                                              â”‚
â”‚   1170 â”‚   def start(self) -> None:                                          â”‚
â”‚   1171 â”‚   â”‚   """Start the progress display."""                             â”‚
â”‚   1172 â”‚   â”‚   if not self.disable:                                          â”‚
â”‚ â± 1173 â”‚   â”‚   â”‚   self.live.start(refresh=True)                             â”‚
â”‚   1174 â”‚                                                                     â”‚
â”‚   1175 â”‚   def stop(self) -> None:                                           â”‚
â”‚   1176 â”‚   â”‚   """Stop the progress display."""                              â”‚
â”‚                                                                              â”‚
â”‚ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ locals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                    â”‚
â”‚ â”‚ self = <rich.progress.Progress object at 0x1416029b0> â”‚                    â”‚
â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯                    â”‚
â”‚                                                                              â”‚
â”‚ /Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site â”‚
â”‚ -packages/rich/live.py:113 in start                                          â”‚
â”‚                                                                              â”‚
â”‚   110 â”‚   â”‚   with self._lock:                                               â”‚
â”‚   111 â”‚   â”‚   â”‚   if self._started:                                          â”‚
â”‚   112 â”‚   â”‚   â”‚   â”‚   return                                                 â”‚
â”‚ â± 113 â”‚   â”‚   â”‚   self.console.set_live(self)                                â”‚
â”‚   114 â”‚   â”‚   â”‚   self._started = True                                       â”‚
â”‚   115 â”‚   â”‚   â”‚   if self._screen:                                           â”‚
â”‚   116 â”‚   â”‚   â”‚   â”‚   self._alt_screen = self.console.set_alt_screen(True)   â”‚
â”‚                                                                              â”‚
â”‚ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ locals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                         â”‚
â”‚ â”‚ refresh = True                                   â”‚                         â”‚
â”‚ â”‚    self = <rich.live.Live object at 0x141603220> â”‚                         â”‚
â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯                         â”‚
â”‚                                                                              â”‚
â”‚ /Users/parkergabel/PycharmProjects/bert-playground/.venv/lib/python3.10/site â”‚
â”‚ -packages/rich/console.py:837 in set_live                                    â”‚
â”‚                                                                              â”‚
â”‚    834 â”‚   â”‚   """                                                           â”‚
â”‚    835 â”‚   â”‚   with self._lock:                                              â”‚
â”‚    836 â”‚   â”‚   â”‚   if self._live is not None:                                â”‚
â”‚ â±  837 â”‚   â”‚   â”‚   â”‚   raise errors.LiveError("Only one live display may be  â”‚
â”‚    838 â”‚   â”‚   â”‚   self._live = live                                         â”‚
â”‚    839 â”‚                                                                     â”‚
â”‚    840 â”‚   def clear_live(self) -> None:                                     â”‚
â”‚                                                                              â”‚
â”‚ â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ locals â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®                            â”‚
â”‚ â”‚ live = <rich.live.Live object at 0x141603220> â”‚                            â”‚
â”‚ â”‚ self = <console width=80 None>                â”‚                            â”‚
â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯                            â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
LiveError: Only one live display may be active at once
