{
  "model_name": "answerdotai/ModernBERT-base",
  "batch_size": 32,
  "learning_rate": 2e-5,
  "num_epochs": 5,
  "max_length": 256,
  "warmup_steps": 100,
  "gradient_accumulation": 1,
  "num_workers": 4,
  "augment": true,
  "experiment_name": "titanic_production",
  "use_mlx_embeddings": false,
  "tokenizer_backend": "auto",
  "configurations": {
    "quick": {
      "description": "Quick test run",
      "num_epochs": 1,
      "batch_size": 64,
      "warmup_steps": 50
    },
    "standard": {
      "description": "Standard training configuration",
      "num_epochs": 5,
      "batch_size": 32,
      "learning_rate": 2e-5,
      "warmup_steps": 100
    },
    "thorough": {
      "description": "Thorough training with smaller batch size",
      "num_epochs": 10,
      "batch_size": 16,
      "learning_rate": 1e-5,
      "warmup_steps": 200,
      "gradient_accumulation": 2
    },
    "mlx_optimized": {
      "description": "Optimized for MLX performance",
      "num_epochs": 5,
      "batch_size": 64,
      "learning_rate": 3e-5,
      "warmup_steps": 100,
      "num_workers": 8,
      "augment": true
    },
    "mlx_embeddings": {
      "description": "Using MLX embeddings backend",
      "use_mlx_embeddings": true,
      "tokenizer_backend": "mlx",
      "model_name": "mlx-community/answerdotai-ModernBERT-base-4bit",
      "num_epochs": 5,
      "batch_size": 32,
      "learning_rate": 2e-5,
      "warmup_steps": 100
    },
    "mlx_embeddings_large": {
      "description": "Using MLX embeddings with large model",
      "use_mlx_embeddings": true,
      "tokenizer_backend": "mlx",
      "model_name": "mlx-community/answerdotai-ModernBERT-large-4bit",
      "num_epochs": 5,
      "batch_size": 16,
      "learning_rate": 1e-5,
      "warmup_steps": 150,
      "gradient_accumulation": 2
    }
  }
}