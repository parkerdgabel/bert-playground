# Development configuration for feature development and debugging
optimizer:
  type: adamw
  learning_rate: 2.0e-5
  weight_decay: 0.01
  beta1: 0.9
  beta2: 0.999
  epsilon: 1.0e-8
  max_grad_norm: 1.0

scheduler:
  type: linear
  warmup_ratio: 0.1
  warmup_steps: 0  # Will be calculated from warmup_ratio

data:
  batch_size: 16
  eval_batch_size: 32
  num_workers: 4
  prefetch_size: 2
  shuffle_train: true
  drop_last: false
  pin_memory: true
  augment_train: false
  augmentation_prob: 0.5

training:
  num_epochs: 5
  max_steps: -1
  gradient_accumulation_steps: 1
  mixed_precision: true
  eval_strategy: epoch
  eval_steps: 500
  eval_delay: 0
  logging_steps: 50
  log_level: info
  report_to: ["mlflow"]
  save_strategy: epoch
  save_steps: 500
  save_total_limit: 3
  save_best_only: false
  best_metric: eval_loss
  best_metric_mode: min
  early_stopping: true
  early_stopping_patience: 2
  early_stopping_threshold: 0.0001
  label_smoothing: 0.0
  dropout_rate: 0.1

environment:
  output_dir: output/dev
  experiment_name: development
  seed: 42
  device: gpu
  gradient_checkpointing: false
  memory_efficient_attention: true
  debug_mode: true
  profile: false
  mlflow_tags:
    environment: development
    framework: mlx