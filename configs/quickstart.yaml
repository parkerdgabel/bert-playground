# Quick start configuration for new users
# Uses small settings for fast testing

model:
  architecture: modernbert
  hidden_size: 768
  num_layers: 12
  num_attention_heads: 12
  intermediate_size: 3072
  max_position_embeddings: 512
  vocab_size: 30522
  type_vocab_size: 2
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  use_compilation: true

training:
  epochs: 3
  batch_size: 8
  gradient_accumulation_steps: 1
  gradient_clipping: 1.0
  mixed_precision: true
  learning_rate: 2e-5
  warmup_steps: 100
  logging_steps: 10
  eval_steps: 50
  save_steps: 100
  metric_for_best_model: "val_accuracy"
  greater_is_better: true
  use_lora: false

optimizer:
  type: adamw
  weight_decay: 0.01
  beta1: 0.9
  beta2: 0.999
  epsilon: 1e-8

scheduler:
  type: linear
  num_warmup_steps: 100

data:
  max_length: 128
  num_workers: 4
  prefetch_size: 2
  use_pretokenized: false
  text_column: "text"
  label_column: "label"

callbacks:
  - type: progress
    update_frequency: 1
  - type: metrics
    log_to_file: true
  - type: early_stopping
    patience: 3
    metric: "val_loss"
    mode: "min"
  - type: checkpoint
    save_best_only: true
    save_frequency: 100

debug:
  verbose: false
  log_level: "INFO"