2025-07-17 09:44:08.412 | INFO     | utils.mlx_patch:apply_mlx_patches:77 - Applying MLX compatibility patches...
2025-07-17 09:44:08.412 | INFO     | utils.mlx_patch:patch_mlx_astype:72 - Applied MLX astype() compatibility patch
2025-07-17 09:44:08.413 | INFO     | utils.mlx_patch:apply_mlx_patches:79 - MLX compatibility patches applied successfully
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.

MLX Unified Training System
============================================================
Loaded config from configs/titanic_production.json

Loading data...
2025-07-17 09:44:12.055 | INFO     | data.mlx_dataloader:__init__:82 - Loading tokenizer: mlx-community/answerdotai-ModernBERT-base-4bit (backend: auto)
2025-07-17 09:44:12.055 | INFO     | embeddings.mlx_adapter:_load_mlx_embeddings:55 - Loading MLX embeddings model: mlx-community/answerdotai-ModernBERT-base-4bit
Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 11538.66it/s]
2025-07-17 09:44:12.332 | INFO     | embeddings.mlx_adapter:_load_mlx_embeddings:58 - Successfully loaded MLX embeddings model
2025-07-17 09:44:12.332 | INFO     | embeddings.tokenizer_wrapper:_initialize_backend:59 - Using MLX embeddings tokenizer
2025-07-17 09:44:12.333 | DEBUG    | data.mlx_dataloader:_analyze_csv:133 - CSV columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']
2025-07-17 09:44:12.333 | DEBUG    | data.mlx_dataloader:_analyze_csv:134 - Text columns: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']
2025-07-17 09:44:12.333 | DEBUG    | data.mlx_dataloader:_analyze_csv:135 - Has labels: True
2025-07-17 09:44:12.333 | INFO     | data.mlx_dataloader:_preprocess_data:139 - Preprocessing data...
2025-07-17 09:44:12.474 | INFO     | data.mlx_dataloader:_preprocess_data:173 - Preprocessed 891 samples
2025-07-17 09:44:12.474 | INFO     | data.mlx_dataloader:__init__:104 - Initialized KaggleDataLoader: 891 samples, 55 batches
2025-07-17 09:44:12.474 | INFO     | data.mlx_dataloader:__init__:82 - Loading tokenizer: mlx-community/answerdotai-ModernBERT-base-4bit (backend: auto)
2025-07-17 09:44:12.474 | INFO     | embeddings.mlx_adapter:_load_mlx_embeddings:55 - Loading MLX embeddings model: mlx-community/answerdotai-ModernBERT-base-4bit
Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 146312.93it/s]
2025-07-17 09:44:12.646 | INFO     | embeddings.mlx_adapter:_load_mlx_embeddings:58 - Successfully loaded MLX embeddings model
2025-07-17 09:44:12.646 | INFO     | embeddings.tokenizer_wrapper:_initialize_backend:59 - Using MLX embeddings tokenizer
2025-07-17 09:44:12.647 | DEBUG    | data.mlx_dataloader:_analyze_csv:133 - CSV columns: ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']
2025-07-17 09:44:12.647 | DEBUG    | data.mlx_dataloader:_analyze_csv:134 - Text columns: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']
2025-07-17 09:44:12.647 | DEBUG    | data.mlx_dataloader:_analyze_csv:135 - Has labels: True
2025-07-17 09:44:12.647 | INFO     | data.mlx_dataloader:_preprocess_data:139 - Preprocessing data...
2025-07-17 09:44:12.677 | INFO     | data.mlx_dataloader:_preprocess_data:173 - Preprocessed 178 samples
2025-07-17 09:44:12.677 | INFO     | data.mlx_dataloader:__init__:104 - Initialized KaggleDataLoader: 178 samples, 5 batches
âœ“ Loaded ~896 training samples (56 batches)
âœ“ Loaded ~192 validation samples (6 batches)
2025-07-17 09:44:12.678 | INFO     | training.config:_validate_config:373 - Configuration validation passed
                          Training Configuration                          
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Parameter             â”ƒ Value                                          â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Model                 â”‚ mlx-community/answerdotai-ModernBERT-base-4bit â”‚
â”‚ Model Type            â”‚ base                                           â”‚
â”‚ Output Directory      â”‚ output/run_20250717_094412                     â”‚
â”‚ MLX Embeddings        â”‚ Enabled                                        â”‚
â”‚ Tokenizer Backend     â”‚ auto                                           â”‚
â”‚ Batch Size            â”‚ 16                                             â”‚
â”‚ Learning Rate         â”‚ 5e-05                                          â”‚
â”‚ Epochs                â”‚ 10                                             â”‚
â”‚ Gradient Accumulation â”‚ 1                                              â”‚
â”‚ MLflow                â”‚ Enabled                                        â”‚
â”‚ Early Stopping        â”‚ 5                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
2025-07-17 09:44:12.682 | INFO     | models.embeddings.mlx_adapter:_load_mlx_embeddings:55 - Loading MLX embeddings model: mlx-community/answerdotai-ModernBERT-base-4bit
Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]Fetching 6 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 14873.42it/s]
2025-07-17 09:44:12.881 | INFO     | models.embeddings.mlx_adapter:_load_mlx_embeddings:58 - Successfully loaded MLX embeddings model
2025-07-17 09:44:12.881 | INFO     | models.embeddings.embedding_model:__init__:64 - Initialized EmbeddingModel: mlx-community/answerdotai-ModernBERT-base-4bit (hidden_size=768)
2025-07-17 09:44:12.881 | INFO     | models.classification.titanic_classifier:__init__:64 - Initialized TitanicClassifier with mlx-community/answerdotai-ModernBERT-base-4bit
2025-07-17 09:44:12.881 | INFO     | models.classification.factory:create_classifier:126 - Created titanic classifier with mlx-community/answerdotai-ModernBERT-base-4bit
âœ“ Created New Architecture MLX Embeddings ModernBERT model
2025-07-17 09:44:12.882 | INFO     | training.rich_display_manager:__init__:52 - Initialized RichDisplayManager
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[32m2025-07-17 09:44:12[0m | [1mINFO    [0m | [36mtraining.memory_manager[0m:[36m__init__[0m:[36m82[0m - [1mMemory Manager initialized:
  Apple Silicon: True
  Unified Memory: 32.00 GB
  Optimal Usage: 64.0%
  Target Memory: 20.48 GB[0m
[32m2025-07-17 09:44:12[0m | [1mINFO    [0m | [36mtraining.performance_profiler[0m:[36m__init__[0m:[36m101[0m - [1mPerformance Profiler initialized:
  Apple Silicon: True
  Neural Engine: True
  Thermal Monitoring: True
  Power Monitoring: True[0m
2025/07/17 09:44:13 INFO mlflow.store.db.utils: Creating initial MLflow database tables...
2025/07/17 09:44:13 INFO mlflow.store.db.utils: Updating database tables
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
2025/07/17 09:44:13 INFO mlflow.tracking.fluent: Experiment with name 'titanic_production' does not exist. Creating a new experiment.
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.mlflow_central[0m:[36minitialize[0m:[36m83[0m - [1mMLflow initialized with central configuration:
  Tracking URI: sqlite:///mlruns/mlflow.db
  Artifact Root: ./mlruns/artifacts
  Experiment: titanic_production[0m
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[32m2025-07-17 09:44:13[0m | [33m[1mWARNING [0m | [36mtraining.monitoring[0m:[36m_log_config_params[0m:[36m234[0m - [33m[1mFailed to log config parameters: 'MemoryConfig' object has no attribute 'gradient_accumulation_steps'[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36m_initialize_mlflow[0m:[36m185[0m - [1mStarted MLflow run: ec5245dbb43d47f9b0c5d96941b47560[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36m__init__[0m:[36m642[0m - [1mInitialized comprehensive monitoring system[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36m_apply_apple_silicon_optimizations[0m:[36m1069[0m - [1mApplying Apple Silicon optimizations...[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36m__init__[0m:[36m144[0m - [1mInitialized Production MLX Trainer:
  Model: TitanicClassifier
  Optimization Level: auto
  Batch Size: 16 (effective: 16)
  Learning Rate: 5e-05
  Epochs: 10
  Apple Silicon: True
  MLflow Enabled: True
  Rich Console: False
  Output Dir: output/run_20250717_094412[0m

Starting training...

[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mtraining.rich_display_manager[0m:[36mstart[0m:[36m101[0m - [1mStarted RichDisplayManager[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__enter__[0m:[36m128[0m - [1m============================================================[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__enter__[0m:[36m129[0m - [1mStarting experiment: titanic_production[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__enter__[0m:[36m130[0m - [1mStart time: 2025-07-17 09:44:13.767628[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__enter__[0m:[36m131[0m - [1m============================================================[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m99[0m - [1mHyperparameters:[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  epochs: 10[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  batch_size: 16[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  learning_rate: 5e-05[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  warmup_steps: 28[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  max_steps: None[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  model_name: answerdotai/ModernBERT-base[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  model_type: modernbert[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  max_length: 256[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  num_labels: None[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  train_path: data/titanic/train.csv[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  val_path: data/titanic/val.csv[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  test_path: None[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  target_column: None[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  optimizer: adamw[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  lr_schedule: cosine_warmup[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  loss_function: cross_entropy[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  optimization_level: auto[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  memory: {'enable_memory_profiling': True, 'memory_limit_gb': None, 'dynamic_batch_sizing': True, 'min_batch_size': 4, 'max_batch_size': 128, 'memory_check_interval': 100, 'unified_memory_fraction': 0.8, 'enable_memory_pool': True, 'force_garbage_collection': True, 'gc_interval': 500}[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  mlx_optimization: {'enable_lazy_evaluation': True, 'eval_frequency': 10, 'enable_gradient_checkpointing': False, 'gradient_accumulation_steps': 1, 'max_grad_norm': 1.0, 'device_placement_strategy': 'auto', 'enable_multi_device': False, 'mixed_precision': False, 'precision_dtype': 'float32', 'enable_jit': True, 'optimize_memory_layout': True}[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  monitoring: {'enable_mlflow': True, 'experiment_name': 'titanic_production', 'run_name': 'base_20250717_094412', 'tracking_uri': None, 'log_level': 'INFO', 'log_to_file': True, 'log_file_path': 'output/run_20250717_094412/training.log', 'enable_rich_console': False, 'log_frequency': 10, 'eval_frequency': 500, 'save_frequency': 1000, 'enable_progress_bar': True, 'progress_bar_style': 'rich', 'track_gradients': False, 'track_weights': False, 'track_memory': True, 'track_performance': True}[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  checkpoint: {'enable_checkpointing': True, 'checkpoint_dir': 'output/run_20250717_094412/output/run_20250717_094412/checkpoints', 'checkpoint_frequency': 50, 'save_optimizer_state': True, 'save_scheduler_state': True, 'save_random_state': True, 'save_model_weights': True, 'max_checkpoints_to_keep': 5, 'save_best_model': True, 'best_model_metric': 'val_accuracy', 'best_model_mode': 'max', 'auto_resume': True, 'resume_from_checkpoint': None, 'use_safetensors': True, 'compress_checkpoints': False}[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  evaluation: {'eval_during_training': True, 'eval_steps': 25, 'eval_strategy': 'steps', 'primary_metric': 'accuracy', 'metrics_to_compute': ['accuracy', 'precision', 'recall', 'f1', 'auc'], 'enable_early_stopping': True, 'early_stopping_patience': 5, 'early_stopping_threshold': 0.001, 'early_stopping_metric': 'val_loss', 'early_stopping_mode': 'min', 'validation_split': 0.2, 'validation_batch_size': None, 'test_at_end': True, 'generate_predictions': True, 'save_predictions': True}[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  advanced: {'label_smoothing': 0.1, 'dropout_rate': 0.1, 'weight_decay': 0.01, 'enable_augmentation': True, 'augmentation_probability': 0.5, 'enable_curriculum_learning': False, 'curriculum_strategy': 'difficulty', 'curriculum_pace': 0.1, 'enable_ensembling': False, 'ensemble_size': 1, 'ensemble_strategy': 'averaging', 'enable_distillation': False, 'teacher_model_path': None, 'distillation_temperature': 3.0, 'distillation_alpha': 0.5, 'enable_hpo': False, 'hpo_backend': 'optuna', 'hpo_trials': 50, 'hpo_metric': 'val_accuracy'}[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  seed: 42[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  deterministic: True[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  output_dir: output/run_20250717_094412[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  experiment_name: titanic_production[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36mlog_hyperparameters[0m:[36m101[0m - [1m  run_name: base_20250717_094412[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mtraining.config[0m:[36m_auto_configure_optimization[0m:[36m307[0m - [1mAuto-configuring optimization level...[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mtraining.config[0m:[36mupdate_from_dataset[0m:[36m497[0m - [1mAuto-configured optimization level: OptimizationLevel.DEVELOPMENT[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mtrain[0m:[36m652[0m - [1mTraining Configuration:
  Steps per epoch: 56
  Total steps: 560
  Effective batch size: 16
  Warmup steps: 28[0m
[32m2025-07-17 09:44:13[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36mstart_training[0m:[36m652[0m - [1mStarted training monitoring: 10 epochs, 56 steps/epoch[0m
[32m2025-07-17 09:44:25[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m474[0m - [1mStarting validation evaluation[0m
[32m2025-07-17 09:44:27[0m | [33m[1mWARNING [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m565[0m - [33m[1mCould not compute AUC: Input contains NaN.[0m
[32m2025-07-17 09:44:27[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m567[0m - [1mValidation Results: Loss=nan, Acc=0.6573, F1=0.0000[0m
[32m2025-07-17 09:44:27[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36mlog_validation[0m:[36m753[0m - [1mValidation metrics improved at step 25[0m
[32m2025-07-17 09:44:27[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36mlog_validation[0m:[36m755[0m - [1m  Best val_loss: nan[0m
[32m2025-07-17 09:44:27[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36mlog_validation[0m:[36m757[0m - [1m  Best val_accuracy: 0.6573[0m
[32m2025-07-17 09:44:27[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m585[0m - [1mNew best validation metrics at step 25[0m
[32m2025-07-17 09:44:27[0m | [31m[1mERROR   [0m | [36mtraining.mlx_trainer[0m:[36m_save_checkpoint[0m:[36m982[0m - [31m[1mFailed to save checkpoint: 'TitanicClassifier' object has no attribute 'save_pretrained'[0m
[32m2025-07-17 09:44:39[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m474[0m - [1mStarting validation evaluation[0m
[32m2025-07-17 09:44:41[0m | [33m[1mWARNING [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m565[0m - [33m[1mCould not compute AUC: Input contains NaN.[0m
[32m2025-07-17 09:44:41[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m567[0m - [1mValidation Results: Loss=nan, Acc=0.6573, F1=0.0000[0m
[32m2025-07-17 09:44:44[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mtrain[0m:[36m688[0m - [1mEpoch 1/10 completed: Loss=nan, Time=30.6s[0m
[32m2025-07-17 09:44:53[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m474[0m - [1mStarting validation evaluation[0m
[32m2025-07-17 09:44:55[0m | [33m[1mWARNING [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m565[0m - [33m[1mCould not compute AUC: Input contains NaN.[0m
[32m2025-07-17 09:44:55[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m567[0m - [1mValidation Results: Loss=nan, Acc=0.6573, F1=0.0000[0m
[32m2025-07-17 09:45:06[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m474[0m - [1mStarting validation evaluation[0m
[32m2025-07-17 09:45:08[0m | [33m[1mWARNING [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m565[0m - [33m[1mCould not compute AUC: Input contains NaN.[0m
[32m2025-07-17 09:45:08[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m567[0m - [1mValidation Results: Loss=nan, Acc=0.6573, F1=0.0000[0m
[32m2025-07-17 09:45:08[0m | [31m[1mERROR   [0m | [36mtraining.mlx_trainer[0m:[36m_save_checkpoint[0m:[36m982[0m - [31m[1mFailed to save checkpoint: 'TitanicClassifier' object has no attribute 'save_pretrained'[0m
[32m2025-07-17 09:45:14[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mtrain[0m:[36m688[0m - [1mEpoch 2/10 completed: Loss=nan, Time=29.8s[0m
[32m2025-07-17 09:45:20[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m474[0m - [1mStarting validation evaluation[0m
[32m2025-07-17 09:45:22[0m | [33m[1mWARNING [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m565[0m - [33m[1mCould not compute AUC: Input contains NaN.[0m
[32m2025-07-17 09:45:22[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m567[0m - [1mValidation Results: Loss=nan, Acc=0.6573, F1=0.0000[0m
[32m2025-07-17 09:45:35[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m474[0m - [1mStarting validation evaluation[0m
[32m2025-07-17 09:45:37[0m | [33m[1mWARNING [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m565[0m - [33m[1mCould not compute AUC: Input contains NaN.[0m
[32m2025-07-17 09:45:37[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m567[0m - [1mValidation Results: Loss=nan, Acc=0.6573, F1=0.0000[0m
[32m2025-07-17 09:45:45[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mtrain[0m:[36m688[0m - [1mEpoch 3/10 completed: Loss=nan, Time=31.0s[0m
[32m2025-07-17 09:45:48[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m474[0m - [1mStarting validation evaluation[0m
[32m2025-07-17 09:45:50[0m | [33m[1mWARNING [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m565[0m - [33m[1mCould not compute AUC: Input contains NaN.[0m
[32m2025-07-17 09:45:50[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m567[0m - [1mValidation Results: Loss=nan, Acc=0.6573, F1=0.0000[0m
[32m2025-07-17 09:46:01[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m474[0m - [1mStarting validation evaluation[0m
[32m2025-07-17 09:46:03[0m | [33m[1mWARNING [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m565[0m - [33m[1mCould not compute AUC: Input contains NaN.[0m
[32m2025-07-17 09:46:03[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m567[0m - [1mValidation Results: Loss=nan, Acc=0.6573, F1=0.0000[0m
[32m2025-07-17 09:46:03[0m | [31m[1mERROR   [0m | [36mtraining.mlx_trainer[0m:[36m_save_checkpoint[0m:[36m982[0m - [31m[1mFailed to save checkpoint: 'TitanicClassifier' object has no attribute 'save_pretrained'[0m
[32m2025-07-17 09:46:14[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mtrain[0m:[36m688[0m - [1mEpoch 4/10 completed: Loss=nan, Time=29.6s[0m
[32m2025-07-17 09:46:15[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m474[0m - [1mStarting validation evaluation[0m
[32m2025-07-17 09:46:17[0m | [33m[1mWARNING [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m565[0m - [33m[1mCould not compute AUC: Input contains NaN.[0m
[32m2025-07-17 09:46:17[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m567[0m - [1mValidation Results: Loss=nan, Acc=0.6573, F1=0.0000[0m
[32m2025-07-17 09:46:28[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m474[0m - [1mStarting validation evaluation[0m
[32m2025-07-17 09:46:30[0m | [33m[1mWARNING [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m565[0m - [33m[1mCould not compute AUC: Input contains NaN.[0m
[32m2025-07-17 09:46:30[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m567[0m - [1mValidation Results: Loss=nan, Acc=0.6573, F1=0.0000[0m
[32m2025-07-17 09:46:42[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m474[0m - [1mStarting validation evaluation[0m
[32m2025-07-17 09:46:44[0m | [33m[1mWARNING [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m565[0m - [33m[1mCould not compute AUC: Input contains NaN.[0m
[32m2025-07-17 09:46:44[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m567[0m - [1mValidation Results: Loss=nan, Acc=0.6573, F1=0.0000[0m
[32m2025-07-17 09:46:46[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mtrain[0m:[36m688[0m - [1mEpoch 5/10 completed: Loss=nan, Time=31.8s[0m
[32m2025-07-17 09:46:46[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mshould_stop_early[0m:[36m616[0m - [1mEarly stopping triggered: No improvement for 5 evaluations[0m
[32m2025-07-17 09:46:46[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mtrain[0m:[36m700[0m - [1mEarly stopping at epoch 5[0m
[32m2025-07-17 09:46:46[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36m_final_evaluation[0m:[36m884[0m - [1mRunning final validation evaluation[0m
[32m2025-07-17 09:46:46[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m474[0m - [1mStarting final_validation evaluation[0m
[32m2025-07-17 09:46:48[0m | [33m[1mWARNING [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m565[0m - [33m[1mCould not compute AUC: Input contains NaN.[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mevaluate[0m:[36m567[0m - [1mFinal_validation Results: Loss=nan, Acc=0.6573, F1=0.0000[0m
[32m2025-07-17 09:46:48[0m | [31m[1mERROR   [0m | [36mtraining.mlx_trainer[0m:[36m_save_checkpoint[0m:[36m982[0m - [31m[1mFailed to save checkpoint: 'TitanicClassifier' object has no attribute 'save_pretrained'[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mtraining.memory_manager[0m:[36msave_memory_report[0m:[36m417[0m - [1mMemory report saved to: output/run_20250717_094412/memory_report.json[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mtraining.performance_profiler[0m:[36msave_performance_report[0m:[36m561[0m - [1mPerformance report saved to: output/run_20250717_094412/performance_report.json[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36mend_run[0m:[36m279[0m - [1mEnded MLflow run: ec5245dbb43d47f9b0c5d96941b47560 with status: FINISHED[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36mend_training[0m:[36m847[0m - [1mTraining monitoring ended with status: FINISHED[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mtraining.monitoring[0m:[36mend_training[0m:[36m848[0m - [1mTotal time: 154.8s, Steps: 280[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mtraining.memory_manager[0m:[36msave_memory_report[0m:[36m417[0m - [1mMemory report saved to: output/run_20250717_094412/memory_report.json[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mtraining.performance_profiler[0m:[36msave_performance_report[0m:[36m561[0m - [1mPerformance report saved to: output/run_20250717_094412/performance_report.json[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36m_save_advanced_reports[0m:[36m1110[0m - [1mAdvanced profiling reports saved successfully[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mtraining.mlx_trainer[0m:[36mtrain[0m:[36m747[0m - [1mTraining completed in 154.8s
Best metric: 0.6573 at step 25[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m142[0m - [1m============================================================[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m143[0m - [1mExperiment completed: titanic_production[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m144[0m - [1mEnd time: 2025-07-17 09:46:48.588439[0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m145[0m - [1mDuration: 0:02:34.820811[0m
[32m2025-07-17 09:46:48[0m | [32m[1mSUCCESS [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m151[0m - [32m[1mExperiment completed successfully![0m
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mutils.logging_config[0m:[36m__exit__[0m:[36m153[0m - [1m============================================================[0m
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Training completed in 154.8s                                                 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
â•­â”€â”€â”€â”€â”€â”€â”€ Metrics â”€â”€â”€â”€â”€â”€â”€â”€â•®â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Progress â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”“ â”‚â”‚ â ‹ Epoch 1/10                            0% -:--:-- â”‚
â”‚ â”ƒ Metric  â”ƒ Value    â”ƒ â”‚â”‚ â ‹ Evaluating validation                 0% -:--:-- â”‚
â”‚ â”¡â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”© â”‚â”‚ â ‹ Evaluating validation                 0% -:--:-- â”‚
â”‚ â”‚ No      â”‚ Availabâ€¦ â”‚ â”‚â”‚ â ‹ Epoch 2/10                            0% -:--:-- â”‚
â”‚ â”‚ metrics â”‚          â”‚ â”‚â”‚ â ‹ Evaluating validation                 0% -:--:-- â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚â”‚ â ‹ Evaluating validation                 0% -:--:-- â”‚
â”‚                        â”‚â”‚ â ‹ Epoch 3/10                            0% -:--:-- â”‚
â”‚                        â”‚â”‚ â ‹ Evaluating validation                 0% -:--:-- â”‚
â”‚                        â”‚â”‚ â ‹ Evaluating validation                 0% -:--:-- â”‚
â”‚                        â”‚â”‚ â ‹ Epoch 4/10                            0% -:--:-- â”‚
â”‚                        â”‚â”‚ â ‹ Evaluating validation                 0% -:--:-- â”‚
â”‚                        â”‚â”‚ â ‹ Evaluating validation                 0% -:--:-- â”‚
â”‚                        â”‚â”‚ â ‹ Epoch 5/10                            0% -:--:-- â”‚
â”‚                        â”‚â”‚ â ‹ Evaluating validation                 0% -:--:-- â”‚
â”‚                        â”‚â”‚ â ‹ Evaluating validation                 0% -:--:-- â”‚
â”‚                        â”‚â”‚ â ‹ Evaluating validation                 0% -:--:-- â”‚
â”‚                        â”‚â”‚ â ‹ Evaluating final_validation           0% -:--:-- â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ MLX BERT Training - 09:46:48                                                 â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
[32m2025-07-17 09:46:48[0m | [1mINFO    [0m | [36mtraining.rich_display_manager[0m:[36mstop[0m:[36m119[0m - [1mStopped RichDisplayManager[0m

âœ“ Training completed in 154.8s
           Training Results            
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ Metric                     â”ƒ Value  â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ Best Validation Score      â”‚ 0.6573 â”‚
â”‚ Best Step                  â”‚ 25     â”‚
â”‚ Total Time                 â”‚ 154.8s â”‚
â”‚ final_validation_loss      â”‚ nan    â”‚
â”‚ final_validation_accuracy  â”‚ 0.6573 â”‚
â”‚ final_validation_precision â”‚ 0.0000 â”‚
â”‚ final_validation_recall    â”‚ 0.0000 â”‚
â”‚ final_validation_f1        â”‚ 0.0000 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Results saved to: output/run_20250717_094412

View results with: mlflow ui
